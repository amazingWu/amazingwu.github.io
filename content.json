{"meta":{"title":"AmazingWu","subtitle":"吴琪个人博客","description":"目前就读于北京理工大学软件学院","author":"AmazingWu","url":"http://amazingwu.xyz"},"pages":[{"title":"关于我","date":"2017-04-09T04:44:43.000Z","updated":"2017-05-09T06:21:57.014Z","comments":true,"path":"about/index.html","permalink":"http://amazingwu.xyz/about/index.html","excerpt":"","text":"地理位置: 教育背景: M.A. : Beijing Institute Of Technology ， Software Engineering ， 2016.09 - Present 个人信息：&emsp;&emsp;目前在北京理工大学软件学院数据科学研究所研究大数据方向 性格：&emsp;&emsp;简单，随性，放纵不羁，爱自由 个人信息：&emsp;&emsp;个人github地址：https://github.com/amazingWu&emsp;&emsp;个人CSDN博客：http://blog.csdn.net/u013668852&emsp;&emsp;个人邮箱：amazingjadewu@gmail.com&emsp;&emsp;欢迎添加我的微信： wq951654775 友情链接：&emsp;&emsp;HaroldLiuChi:北京理工大学软件学院副院长刘驰老师&emsp;&emsp;Guangyu(Ryan) Gao:北京理工大学软件学院高老师&emsp;&emsp;FangHeart的博客:实验室小伙伴FangHeart&emsp;&emsp;wenjiewang的博客：实验室小伙伴wenjiewang&emsp;&emsp;DuanXiong的博客：实验室小伙伴DuanXiong var duoshuoQuery = {short_name:”&lt;%= theme.duoshuo_shortname %&gt;”}; (function() { var ds = document.createElement(‘script’); ds.type = ‘text/javascript’;ds.async = true; ds.src = (document.location.protocol == ‘https:’ ? ‘https:’ : ‘http:’) + ‘//static.duoshuo.com/embed.js’; ds.charset = ‘UTF-8’; (document.getElementsByTagName(‘head’)[0] || document.getElementsByTagName(‘body’)[0]).appendChild(ds); })();"},{"title":"相册","date":"2017-04-10T11:34:02.000Z","updated":"2017-04-10T11:38:55.614Z","comments":true,"path":"photo/index.html","permalink":"http://amazingwu.xyz/photo/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-04-09T04:50:07.000Z","updated":"2017-04-09T07:36:09.336Z","comments":true,"path":"tags/index.html","permalink":"http://amazingwu.xyz/tags/index.html","excerpt":"","text":""},{"title":"感兴趣的项目","date":"2017-04-10T11:34:59.000Z","updated":"2017-04-10T11:38:38.290Z","comments":true,"path":"project/index.html","permalink":"http://amazingwu.xyz/project/index.html","excerpt":"","text":""},{"title":"categories","date":"2017-04-09T04:44:03.000Z","updated":"2017-04-09T07:37:05.986Z","comments":true,"path":"categories/index.html","permalink":"http://amazingwu.xyz/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"机器学习初涉—-决策树分类","slug":"机器学习初涉—-决策树分类","date":"2017-05-08T06:42:49.000Z","updated":"2017-05-08T06:46:25.005Z","comments":true,"path":"2017/05/08/机器学习初涉—-决策树分类/","link":"","permalink":"http://amazingwu.xyz/2017/05/08/机器学习初涉—-决策树分类/","excerpt":"决策树分类我在csdn上进行过介绍，传送门：决策树分类算法http://blog.csdn.net/u013668852/article/details/52935169","text":"决策树分类我在csdn上进行过介绍，传送门：决策树分类算法http://blog.csdn.net/u013668852/article/details/52935169","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://amazingwu.xyz/categories/机器学习/"},{"name":"算法","slug":"机器学习/算法","permalink":"http://amazingwu.xyz/categories/机器学习/算法/"},{"name":"分类算法","slug":"机器学习/算法/分类算法","permalink":"http://amazingwu.xyz/categories/机器学习/算法/分类算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://amazingwu.xyz/tags/算法/"},{"name":"机器学习","slug":"机器学习","permalink":"http://amazingwu.xyz/tags/机器学习/"},{"name":"分类算法","slug":"分类算法","permalink":"http://amazingwu.xyz/tags/分类算法/"}]},{"title":"动态规划-DAG-硬币问题","slug":"动态规划-DAG-硬币问题","date":"2017-04-17T13:37:21.000Z","updated":"2017-04-18T00:48:35.920Z","comments":true,"path":"2017/04/17/动态规划-DAG-硬币问题/","link":"","permalink":"http://amazingwu.xyz/2017/04/17/动态规划-DAG-硬币问题/","excerpt":"题目：有n种硬币，面值分别为V1,V2,…Vn,每种都有无限多。给定非负整数S，可以选用多少个硬币，使得面值之和恰好为S？输出硬币数目的最小值和最大值！ &emsp;&emsp;如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元？ (表面上这道题可以用贪心算法，但贪心算法无法保证可以求出解，比如1元换成2元的时候)","text":"题目：有n种硬币，面值分别为V1,V2,…Vn,每种都有无限多。给定非负整数S，可以选用多少个硬币，使得面值之和恰好为S？输出硬币数目的最小值和最大值！ &emsp;&emsp;如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元？ (表面上这道题可以用贪心算法，但贪心算法无法保证可以求出解，比如1元换成2元的时候) &emsp;&emsp;首先我们思考一个问题，如何用最少的硬币凑够i元(i&lt;11)？为什么要这么问呢？两个原因：1.当我们遇到一个大问题时，总是习惯把问题的规模变小，这样便于分析讨论。2.这个规模变小后的问题和原来的问题是同质的，除了规模变小，其它的都是一样的，本质上它还是同一个问题(规模变小后的问题其实是原问题的子问题)。 &emsp;&emsp;好了，让我们从最小的i开始吧。当i=0，即我们需要多少个硬币来凑够0元。由于1，3，5都大于0，即没有比0小的币值，因此凑够0元我们最少需要0个硬币。这时候我们发现用一个标记来表示这句“凑够0元我们最少需要0个硬币。 &emsp;&emsp;那么， 我们用d(i)=j来表示凑够i元最少需要j个硬币。于是我们已经得到了d(0)=0，表示凑够0元最小需要0个硬币。当i=1时，只有面值为1元的硬币可用，因此我们拿起一个面值为1的硬币，接下来只需要凑够0元即可，而这个是已经知道答案的，即d(0)=0。所以，d(1)=d(1-1)+1=d(0)+1=0+1=1。 当i=2时， 仍然只有面值为1的硬币可用，于是我拿起一个面值为1的硬币，接下来我只需要再凑够2-1=1元即可(记得要用最小的硬币数量)，而这个答案也已经知道了。所以d(2)=d(2-1)+1=d(1)+1=1+1=2。 &emsp;&emsp;一直到这里，你都可能会觉得，好无聊，感觉像做小学生的题目似的。因为我们一直都只能操作面值为1的硬币！耐心点，让我们看看i=3时的情况。当i=3时，我们能用的硬币就有两种了：1元的和3元的(5元的仍然没用，因为你需要凑的数目是3元！5元太多了亲)。既然能用的硬币有两种，我就有两种方案。如果我拿了一个1元的硬币，我的目标就变为了:凑够3-1=2元需要的最少硬币数量。即d(3)=d(3-1)+1=d(2)+1=2+1=3。这个方案说的是，我拿3个1元的硬币；第二种方案是我拿起一个3元的硬币，我的目标就变成：凑够3-3=0元需要的最少硬币数量。即d(3)=d(3-3)+1=d(0)+1=0+1=1. &emsp;&emsp;这个方案说的是，我拿1个3元的硬币。好了，这两种方案哪种更优呢？ 记得我们可是要用最少的硬币数量来凑够3元的。所以， 选择d(3)=1，怎么来的呢？ &emsp;&emsp;具体是这样得到的：d(3)=min{d(3-1)+1, d(3-3)+1}。 &emsp;&emsp;上文中d(i)表示凑够i元需要的最少硬币数量，我们将它定义为该问题的”状态”，这个状态是怎么找出来的呢？我在另一篇文章中写过：根据子问题定义状态。你找到子问题，状态也就浮出水面了。 &emsp;&emsp;最终我们要求解的问题，可以用这个状态来表示：d(11)，即凑够11元最少需要多少个硬币。 那状态转移方程是什么呢？既然我们用d(i)表示状态，那么状态转移方程自然包含d(i)， 上文中包含状态d(i)的方程是：d(3)=min{d(3-1)+1,d(3-3)+1}。没错，它就是状态转移方程，描述状态之间是如何转移的。当然，我们要对它抽象一下，d(i)=min{ d(i-vj)+1 }，其中i-vj &gt;=0，vj表示第j个硬币的面值; &emsp;&emsp;有了状态和状态转移方程，这个问题基本上也就解决了。 123456789101112131415161718192021222324252627282930313233#include&lt;cstdio&gt; #include&lt;cstring&gt; int d[1000],v[10]; int max(int a, int b) &#123; return a &gt; b ? a : b; &#125; int dpmax(int s,int n) &#123; if(s&lt;0) return -2&lt;&lt;30; if (d[s] != -1) return d[s]; d[s] = -2&lt;&lt;30;//用于设定不能走到终点的路肯定小于能走到终点的路 for (int i = 0;i &lt; n;i++) if (s &gt;= v[i])//等号很关键 //根据公式：max&#123;dpmax(s-v[i])+1&#125;,代码max(d[s], dpmax(s - v[i], n)+1)中的d[s]记录的是上一个值 d[s] = max(d[s], dpmax(s - v[i], n)+1); return d[s]; &#125; int main() &#123; int n, s, i; while (scanf(\"%d%d\", &amp;n, &amp;s) != EOF) &#123; for (i = 0;i &lt; n;i++) scanf(\"%d\", &amp;v[i]); memset(d, -1, sizeof d); d[0] = 0;//用于辨别该路能否走到终点 printf(\"%d\\n\", dpmax(s, n)); &#125; return 0; &#125; 解答转载自http://www.cnblogs.com/sunTin/p/6674945.html","categories":[{"name":"算法","slug":"算法","permalink":"http://amazingwu.xyz/categories/算法/"},{"name":"动态规划","slug":"算法/动态规划","permalink":"http://amazingwu.xyz/categories/算法/动态规划/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://amazingwu.xyz/tags/算法/"},{"name":"动态规划","slug":"动态规划","permalink":"http://amazingwu.xyz/tags/动态规划/"}]},{"title":"maven打造可执行war包","slug":"maven打造可执行jar包","date":"2017-04-07T07:45:55.000Z","updated":"2017-04-12T10:50:26.354Z","comments":true,"path":"2017/04/07/maven打造可执行jar包/","link":"","permalink":"http://amazingwu.xyz/2017/04/07/maven打造可执行jar包/","excerpt":"在开发java Web时，有时我们会使用嵌入式jetty来运行，项目完成后，如果能够直接运行war包从而启动jetty来运行war包那就非常完美了，本文将讲解如何在项目中整合jetty 9，并构造可执行的war包（打包前和打包后都能随时启动）。","text":"在开发java Web时，有时我们会使用嵌入式jetty来运行，项目完成后，如果能够直接运行war包从而启动jetty来运行war包那就非常完美了，本文将讲解如何在项目中整合jetty 9，并构造可执行的war包（打包前和打包后都能随时启动）。1.首先添加jetty 9的依赖（本文暂时只用到了jetty的以下依赖，读者根据自己的项目需要增加）12345678910&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;version&gt;9.2.7.v20150116&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-webapp&lt;/artifactId&gt; &lt;version&gt;9.2.7.v20150116&lt;/version&gt;&lt;/dependency&gt; 2.项目中使用jetty 9。 首先我封装了自己的JettyServer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class EmbeddedServer &#123; //public static final Logger logger = LoggerFactory.getLogger(EmbeddedServer.class); // private static final int DEFAULT_BUFFER_SIZE = 16192; protected final Server server = new Server(); public EmbeddedServer(int port,String path) throws IOException&#123; this(port,path,false,null); &#125; /** * use war to start * @param port * @param isWar * @param warPath * @throws IOException */ public EmbeddedServer(int port,boolean isWar,String warPath) throws IOException&#123; this(port,null,isWar,warPath); &#125; private EmbeddedServer(int port, String path,boolean isWar,String warPath) throws IOException &#123; Connector connector = getConnector(port); server.addConnector(connector); WebAppContext application = getWebAppContext(path,isWar,warPath); server.setHandler(application); server.setStopAtShutdown(true); &#125; protected WebAppContext getWebAppContext(String path,boolean isWar,String warPath) &#123; WebAppContext application; if(isWar)&#123; application=new WebAppContext(); application.setWar(warPath); return application; &#125;else&#123; application = new WebAppContext(path, \"/\"); application.setConfigurationDiscovered(true); application.setParentLoaderPriority(true); application.setClassLoader(Thread.currentThread().getContextClassLoader()); return application; &#125; &#125; protected Connector getConnector(int port) throws IOException &#123; HttpConfiguration http_config = new HttpConfiguration(); // this is to enable large header sizes when Kerberos is enabled with AD //final int bufferSize = getBufferSize(); //http_config.setResponseHeaderSize(bufferSize); //http_config.setRequestHeaderSize(bufferSize); ServerConnector connector = new ServerConnector(server, new HttpConnectionFactory(http_config)); connector.setPort(port); connector.setHost(\"0.0.0.0\"); server.addConnector(connector); return connector; &#125; /*protected Integer getBufferSize() &#123; try &#123; Configuration configuration = ApplicationProperties.get(); return configuration.getInt(\"sysimple.jetty.request.buffer.size\", DEFAULT_BUFFER_SIZE); &#125; catch (Exception e) &#123; // do nothing &#125; return DEFAULT_BUFFER_SIZE; &#125;*/ public void start() throws Exception &#123; server.start(); //logger.info(\"********************************************************\"); //logger.info(\"The SySimple Has Started !!!\"); server.join(); &#125; public void stop() &#123; try &#123; server.stop(); &#125; catch (Exception e) &#123; //logger.warn(\"Error during shutdown\", e); &#125; &#125;&#125; 接着可以使用封装好的EmbeddedServer来启动war 12345678910111213141516171819public class StartWeb&#123; private static EmbeddedServer embeddedServer; public static void main(String[] args)&#123; //Start web server int port=3000； try&#123; if(args.length==0)&#123; //该方式能够在开发时快速启动 embeddedServer=new EmbeddedServer(port, \"src/main/webapp\"); &#125;else&#123; //传入war包的路径，该方法能够在打包完成后启动该war包 embeddedServer=new EmbeddedServer(port, true, args[0]); &#125; embeddedServer.start(); &#125;catch(Exception e)&#123; System.exit(0); &#125; &#125;&#125; 注意：打包后如果需要启动war包，需要使用如下的这种批处理命令来启动： 以批处理命令（start.bat）和server.war在同级目录下为例：（以下是start.bat的内容） @echo off set bat_dir=%~dp0 java -jar %bat_dir%/web.war %bat_dir%/web.war 读者可以考虑在代码中得到war包的路径，这样可以在启动时省去传参。 下面是最重要的：使用Maven构建可执行war包 总的来说可执行war包是将war包的结构仿照jar包的结构进行改变，第一个是需要在manifest中标记出主方法，第二个是编译后的代码（包，而非.class）必须放在war包的最外层，最后要能够找到项目的依赖。 ①标记主方法 通过maven-war-plugin在manifest中标记主方法入口 1234567891011&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;org.bit.linc.web.commons.StartWeb&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; ②拷贝（也可以移动）web的所有的代码到war包最外层（使用maven-antrun-plugin） 12345678910111213141516171819202122&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;main-class-placement&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;configuration&gt; &lt;target&gt; &lt;copy todir=\"$&#123;project.build.directory&#125;/$&#123;project.artifactId&#125;/\"&gt; &lt;fileset dir=\"$&#123;project.build.directory&#125;/classes/\"&gt; &lt;include name=\"**/*.*\" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ③ 标记所有依赖的位置（将代码拷贝到war最外层后，会出现依赖的类都找不到的情况，因此需要让war包能够查找到这些依赖） 将maven-war-plugin更改为如下内容： 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;org.bit.linc.web.commons.StartWeb&lt;/mainClass&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;WEB-INF/lib&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; 现在可以构建可执行war包了。 以笔者的项目为例：构建的war包中META-INF/MANIFEST.MF会变成如下内容： Manifest-Version: 1.0 Built-By: wubo Build-Jdk: 1.7.0_17 Class-Path: WEB-INF/lib/commons-0.0.2.jar WEB-INF/lib/commons-configur ation-1.8.jar WEB-INF/lib/commons-lang-2.6.jar WEB-INF/lib/commons-lo gging-1.1.1.jar WEB-INF/lib/slf4j-api-1.7.7.jar WEB-INF/lib/slf4j-log 4j12-1.7.7.jar WEB-INF/lib/log4j-1.2.17.jar WEB-INF/lib/plugins-0.0.2 .jar WEB-INF/lib/clusters-0.0.2.jar WEB-INF/lib/monitors-0.0.2.jar WE B-INF/lib/jetty-server-9.2.7.v20150116.jar WEB-INF/lib/javax.servlet- api-3.1.0.jar WEB-INF/lib/jetty-http-9.2.7.v20150116.jar WEB-INF/lib/ jetty-util-9.2.7.v20150116.jar WEB-INF/lib/jetty-io-9.2.7.v20150116.j ar WEB-INF/lib/jetty-webapp-9.2.7.v20150116.jar WEB-INF/lib/jetty-xml -9.2.7.v20150116.jar WEB-INF/lib/jetty-servlet-9.2.7.v20150116.jar WE B-INF/lib/jetty-security-9.2.7.v20150116.jar WEB-INF/lib/gson-2.3.1.j ar Created-By: Apache Maven 3.3.9 Main-Class: org.bit.linc.web.commons.StartWeb Archiver-Version: Plexus Archiver 其中的Class-Path和Main-Class均已经改变。","categories":[{"name":"maven","slug":"maven","permalink":"http://amazingwu.xyz/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://amazingwu.xyz/tags/maven/"},{"name":"javaWeb","slug":"javaWeb","permalink":"http://amazingwu.xyz/tags/javaWeb/"}]},{"title":"机器学习初涉--贝叶斯分类","slug":"机器学习初涉-贝叶斯分类","date":"2017-04-06T02:48:24.000Z","updated":"2017-05-08T06:36:53.388Z","comments":true,"path":"2017/04/06/机器学习初涉-贝叶斯分类/","link":"","permalink":"http://amazingwu.xyz/2017/04/06/机器学习初涉-贝叶斯分类/","excerpt":"","text":"贝叶斯定理 &emsp;&emsp;这个定理解决了现实生活里经常遇到的问题：已知某条件概率，如何得到两个事件交换后的概率，也就是在已知P(A|B)的情况下如何求得P(B|A)。这里先解释什么是条件概率： &emsp;&emsp;P(A|B) 表示事件B已经发生的前提下，事件A发生的概率，叫做事件B发生下事件A的条件概率。其基本求解公式为：。 &emsp;&emsp;贝叶斯定理之所以有用，是因为我们在生活中经常遇到这种情况：我们可以很容易直接得出P(A|B)，P(B|A)则很难直接得出，但我们更关心P(B|A)，贝叶斯定理就为我们打通从P(A|B)获得P(B|A)的道路。 &emsp;&emsp;下面不加证明地直接给出贝叶斯定理： &emsp;&emsp; 朴素贝叶斯分类朴素贝叶斯分类的原理与流程 &emsp;&emsp;朴素贝叶斯分类是一种十分简单的分类算法，叫它朴素贝叶斯分类是因为这种方法的思想真的很朴素，朴素贝叶斯的思想基础是这样的：对于给出的待分类项，求解在此项出现的条件下各个类别出现的概率，哪个最大，就认为此待分类项属于哪个类别。通俗来说，就好比这么个道理，你在街上看到一个黑人，我问你你猜这哥们哪里来的，你十有八九猜非洲。为什么呢？因为黑人中非洲人的比率最高，当然人家也可能是美洲人或亚洲人，但在没有其它可用信息下，我们会选择条件概率最大的类别，这就是朴素贝叶斯的思想基础。 &emsp;&emsp;朴素贝叶斯分类的正式定义如下：1、设 为一个待分类项，而每个a为x的一个特征属性。2、有类别集合3、计算4、如果，则。 &emsp;&emsp;那么现在的关键就是如何计算第3步中的各个条件概率。我们可以这么做：1、找到一个已知分类的待分类项集合，这个集合叫做训练样本集。2、统计得到在各类别下各个特征属性的条件概率估计。即3、如果各个特征属性是条件独立的，则根据贝叶斯定理有如下推导：因为分母对于所有类别为常数，因为我们只要将分子最大化皆可。又因为各特征属性是条件独立的，所以有：根据上述分析，朴素贝叶斯分类的流程可以由下图表示（暂时不考虑验证）： 可以看到，整个朴素贝叶斯分类分为三个阶段： &emsp;&emsp;第一阶段——准备工作阶段，这个阶段的任务是为朴素贝叶斯分类做必要的准备，主要工作是根据具体情况确定特征属性，并对每个特征属性进行适当划分，然后由人工对一部分待分类项进行分类，形成训练样本集合。这一阶段的输入是所有待分类数据，输出是特征属性和训练样本。这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段，其质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分及训练样本质量决定。 &emsp;&emsp;第二阶段——分类器训练阶段，这个阶段的任务就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率估计，并将结果记录。其输入是特征属性和训练样本，输出是分类器。这一阶段是机械性阶段，根据前面讨论的公式可以由程序自动计算完成。 &emsp;&emsp;第三阶段——应用阶段。这个阶段的任务是使用分类器对待分类项进行分类，其输入是分类器和待分类项，输出是待分类项与类别的映射关系。这一阶段也是机械性阶段，由程序完成。 估计类别下特征属性划分的条件概率及Laplace校准 &emsp;&emsp;这一节讨论P(a|y)的估计。 &emsp;&emsp;由上文看出，计算各个划分的条件概率P(a|y)是朴素贝叶斯分类的关键性步骤，当特征属性为离散值时，只要很方便的统计训练样本中各个划分在每个类别中出现的频率即可用来估计P(a|y)，下面重点讨论特征属性是连续值的情况。 &emsp;&emsp;当特征属性为连续值时，通常假定其值服从高斯分布（也称正态分布）。即： &emsp;&emsp;而 &emsp;&emsp;因此只要计算出训练样本中各个类别中此特征项划分的各均值和标准差，代入上述公式即可得到需要的估计值。均值与标准差的计算在此不再赘述。 &emsp;&emsp;另一个需要讨论的问题就是当P(a|y)=0怎么办，当某个类别下某个特征项划分没有出现时，就是产生这种现象，这会令分类器质量大大降低。为了解决这个问题，我们引入Laplace校准，它的思想非常简单，就是对没类别下所有划分的计数加1，这样如果训练样本集数量充分大时，并不会对结果产生影响，并且解决了上述频率为0的尴尬局面。 朴素贝叶斯分类器的应用一、病人分类的例子 &emsp;&emsp;某个医院早上收了六个门诊病人，如下表。 1234567症状 职业 疾病打喷嚏 护士 感冒 打喷嚏 农夫 过敏 头痛 建筑工人 脑震荡 头痛 建筑工人 感冒 打喷嚏 教师 感冒 头痛 教师 脑震荡 &emsp;&emsp;现在又来了第七个病人，是一个打喷嚏的建筑工人。请问他患上感冒的概率有多大？根据贝叶斯定理： 1P(A|B) = P(B|A) P(A) / P(B) &emsp;&emsp;可得 123P(感冒|打喷嚏x建筑工人) = P(打喷嚏x建筑工人|感冒) x P(感冒) / P(打喷嚏x建筑工人) &emsp;&emsp;假定”打喷嚏”和”建筑工人”这两个特征是独立的，因此，上面的等式就变成了 123P(感冒|打喷嚏x建筑工人) = P(打喷嚏|感冒) x P(建筑工人|感冒) x P(感冒) / P(打喷嚏) x P(建筑工人) &emsp;&emsp;这是可以计算的。 123P(感冒|打喷嚏x建筑工人) = 0.66 x 0.33 x 0.5 / 0.5 x 0.33 = 0.66 &emsp;&emsp;因此，这个打喷嚏的建筑工人，有66%的概率是得了感冒。同理，可以计算这个病人患上过敏或脑震荡的概率。比较这几个概率，就可以知道他最可能得什么病。这就是贝叶斯分类器的基本方法：在统计资料的基础上，依据某些特征，计算各个类别的概率，从而实现分类。 二、账号分类的例子&emsp;&emsp;根据某社区网站的抽样统计，该站10000个账号中有89%为真实账号（设为C0），11%为虚假账号（设为C1）。 12C0 = 0.89 C1 = 0.11 &emsp;&emsp;接下来，就要用统计资料判断一个账号的真实性。假定某一个账号有以下三个特征： 123456F1: 日志数量/注册天数 F2: 好友数量/注册天数 F3: 是否使用真实头像（真实头像为1，非真实头像为0） F1 = 0.1 F2 = 0.2 F3 = 0 &emsp;&emsp;请问该账号是真实账号还是虚假账号？&emsp;&emsp;方法是使用朴素贝叶斯分类器，计算下面这个计算式的值。 1P(F1|C)P(F2|C)P(F3|C)P(C) &emsp;&emsp;虽然上面这些值可以从统计资料得到，但是这里有一个问题：F1和F2是连续变量，不适宜按照某个特定值计算概率。&emsp;&emsp;一个技巧是将连续值变为离散值，计算区间的概率。比如将F1分解成[0, 0.05]、(0.05, 0.2)、[0.2, +∞]三个区间，然后计算每个区间的概率。在我们这个例子中，F1等于0.1，落在第二个区间，所以计算的时候，就使用第二个区间的发生概率。&emsp;&emsp;根据统计资料，可得： 123P(F1|C0) = 0.5, P(F1|C1) = 0.1 P(F2|C0) = 0.7, P(F2|C1) = 0.2 P(F3|C0) = 0.2, P(F3|C1) = 0.9 &emsp;&emsp;因此， 123456P(F1|C0) P(F2|C0) P(F3|C0) P(C0) = 0.5 x 0.7 x 0.2 x 0.89 = 0.0623 P(F1|C1) P(F2|C1) P(F3|C1) P(C1) = 0.1 x 0.2 x 0.9 x 0.11 = 0.00198 &emsp;&emsp;可以看到，虽然这个用户没有使用真实头像，但是他是真实账号的概率，比虚假账号高出30多倍，因此判断这个账号为真。三、性别分类的例子&emsp;&emsp;下面是一组人类身体特征的统计资料。 123456789性别 身高（英尺） 体重（磅） 脚掌（英寸）男 6 180 12 男 5.92 190 11 男 5.58 170 12 男 5.92 165 10 女 5 100 6 女 5.5 150 8 女 5.42 130 7 女 5.75 150 9 &emsp;&emsp;已知某人身高6英尺、体重130磅，脚掌8英寸，请问该人是男是女？&emsp;&emsp;根据朴素贝叶斯分类器，计算下面这个式子的值。 1P(身高|性别) x P(体重|性别) x P(脚掌|性别) x P(性别) &emsp;&emsp;这里的困难在于，由于身高、体重、脚掌都是连续变量，不能采用离散变量的方法计算概率。而且由于样本太少，所以也无法分成区间计算。怎么办？&emsp;&emsp;这时，可以假设男性和女性的身高、体重、脚掌都是正态分布，通过样本计算出均值和方差，也就是得到正态分布的密度函数。有了密度函数，就可以把值代入，算出某一点的密度函数的值。&emsp;&emsp;比如，男性的身高是均值5.855、方差0.035的正态分布。所以，男性的身高为6英尺的概率的相对值等于1.5789（大于1并没有关系，因为这里是密度函数的值，只用来反映各个值的相对可能性）。 &emsp;&emsp;有了这些数据以后，就可以计算性别的分类了。 1234P(身高=6|男) x P(体重=130|男) x P(脚掌=8|男) x P(男) = 6.1984 x e-9P(身高=6|女) x P(体重=130|女) x P(脚掌=8|女) x P(女) = 5.3778 x e-4 &emsp;&emsp;可以看到，女性的概率比男性要高出将近10000倍，所以判断该人为女性。","categories":[{"name":"机器学习","slug":"机器学习","permalink":"http://amazingwu.xyz/categories/机器学习/"},{"name":"算法","slug":"机器学习/算法","permalink":"http://amazingwu.xyz/categories/机器学习/算法/"},{"name":"分类算法","slug":"机器学习/算法/分类算法","permalink":"http://amazingwu.xyz/categories/机器学习/算法/分类算法/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://amazingwu.xyz/tags/算法/"},{"name":"机器学习","slug":"机器学习","permalink":"http://amazingwu.xyz/tags/机器学习/"},{"name":"分类算法","slug":"分类算法","permalink":"http://amazingwu.xyz/tags/分类算法/"}]},{"title":"maven多级项目使用slf4j+log4j，以及自定义配置文件路径","slug":"maven多级项目使用slf4j+log4j以及自定义配置文件路径 - 副本","date":"2017-03-23T07:45:55.000Z","updated":"2017-04-12T10:50:47.522Z","comments":true,"path":"2017/03/23/maven多级项目使用slf4j+log4j以及自定义配置文件路径 - 副本/","link":"","permalink":"http://amazingwu.xyz/2017/03/23/maven多级项目使用slf4j+log4j以及自定义配置文件路径 - 副本/","excerpt":"我的maven多级结构如下： sysimple |--integration |--commons |--pom.xml |--plugins |--pom.xml |--web |--pom.xml |--pom.xml 其中依赖情况是：","text":"我的maven多级结构如下： sysimple |--integration |--commons |--pom.xml |--plugins |--pom.xml |--web |--pom.xml |--pom.xml 其中依赖情况是： web依赖于commons和plugins。plugins依赖于commons。integration中定义了打包的方法与资源文件。 首先在sysimple/pom.xml中管理slf4j的版本： 在&lt;dependencyManagement&gt;&lt;/dependencyManagement&gt;中间添加： &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; 由于所有的模块均引用commons，因此只需要在commons中添加slf4j的依赖即可： &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/dependency&gt; 下面即可使用slf4j，在需要使用的地方以如下方式使用： 123456public class StartWeb &#123; private static final Logger logger = LoggerFactory.getLogger(StartWeb.class); public static void main(String[] args)&#123; logger.info(\"this is a example\"); &#125;&#125; 默认情况下，slf4j-log4j会在src/main/java中查找log4j.properties，如果需要指定配置文件的位置，需要在启动时手动加入Jvm的参数，我的例子中添加了-Dlog4j.configuration=file:../integration/conf/sysimple-log4j.properties。在使用绝对路径时是不需要使用file:的，linux端也不需要file:。在运行的时候，slf4j会根据你指定的路径去加载配置文件。配置文件的内容我给出以下例子， 读者可以另行查找配置文件的格式： log4j.rootLogger=INFO,system.out log4j.appender.system.out=org.apache.log4j.ConsoleAppender log4j.appender.system.out.layout=org.apache.log4j.PatternLayout log4j.appender.system.out.layout.ConversionPattern=SysimpleServer Logger--&gt;%5p{%F:%L}-%m%n log4j.logger.thisProject.file=INFO,thisProject.file.out log4j.appender.thisProject.file.out=org.apache.log4j.DailyRollingFileAppender log4j.appender.thisProject.file.out.File=../integration/logs/sysimple-logs.log log4j.appender.thisProject.file.out.layout=org.apache.log4j.PatternLayout","categories":[{"name":"maven","slug":"maven","permalink":"http://amazingwu.xyz/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://amazingwu.xyz/tags/maven/"},{"name":"log4j","slug":"log4j","permalink":"http://amazingwu.xyz/tags/log4j/"}]},{"title":"jvm垃圾收集算法","slug":"jvm垃圾收集算法","date":"2017-03-15T11:05:36.000Z","updated":"2017-04-12T11:07:19.847Z","comments":true,"path":"2017/03/15/jvm垃圾收集算法/","link":"","permalink":"http://amazingwu.xyz/2017/03/15/jvm垃圾收集算法/","excerpt":"来源：JVM虚拟机 标记-清除法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。 之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 它的主要不足有两个：==一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片==，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。","text":"来源：JVM虚拟机 标记-清除法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。 之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 它的主要不足有两个：==一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片==，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用==内存按容量划分为大小相等的两块，每次只使用其中的一块==。 ==当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉==。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。 复制算法的执行过程如图3-3所示。 现在的商业虚拟机都采用这种收集算法来回收新生代，IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的。所以并不需要按照1:1的比例来划分内存空间，==而是将内存分为一块较大的Eden空间和两块较小的Survivor空间==，每次使用Eden和其中一块Survivor[1]。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 标记整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。 更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，==只是根据对象存活周期的不同将内存划分为几块==。 一般是把Java堆分为新生代和老年代，这样就可以==根据各个年代的特点采用最适当的收集算法==。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、 没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。","categories":[{"name":"jvm","slug":"jvm","permalink":"http://amazingwu.xyz/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://amazingwu.xyz/tags/jvm/"}]},{"title":"java对象的创建过程","slug":"java对象的创建过程","date":"2017-03-15T10:52:36.000Z","updated":"2017-04-12T11:00:19.888Z","comments":true,"path":"2017/03/15/java对象的创建过程/","link":"","permalink":"http://amazingwu.xyz/2017/03/15/java对象的创建过程/","excerpt":"对象的创建过程 来源：JVM虚拟机 Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出来。在语言层面上，创建对象（例如克隆、反序列化）通常仅仅是一个new关键字而已，而在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建又是怎样一个过程呢？","text":"对象的创建过程 来源：JVM虚拟机 Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出来。在语言层面上，创建对象（例如克隆、反序列化）通常仅仅是一个new关键字而已，而在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建又是怎样一个过程呢？虚拟机遇到一条new指令时，==首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过==。 如果没有，那必须先执行相应的类加载过程。 ==在类加载检查通过后，接下来虚拟机将为新生对象分配内存==。==对象所需内存的大小在类加载完成后便可完全确定==（如何确定将在2.3.2节中介绍），为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。++假设Java堆中内存是绝对规整的++，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“++==指针碰撞==++”（Bump the Pointer）。如果Java堆中的内存并++不是规整的++，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“==空闲列表==”（Free List）。 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 因此，在使用Serial、 ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。 除如何划分可用空间之外，还有另外一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案，==一种是对分配内存空间的动作进行同步处理==——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；==另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）==。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。 内存分配完成后，==虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行==。 这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、 如何才能找到类的元数据信息、 对象的哈希码、对象的GC分代年龄等信息。 这些信息存放在对象的对象头（Object Header）之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 关于对象头的具体内容，稍后再做详细介绍。 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——＜init＞方法还没有执行，所有的字段都还为零。所以，一般来说（由字节码中是否跟随invokespecial指令所决定），==执行new指令之后会接着执行＜init＞方法==，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。","categories":[{"name":"jvm","slug":"jvm","permalink":"http://amazingwu.xyz/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://amazingwu.xyz/tags/jvm/"}]},{"title":"Storm和Spark streaming对比","slug":"Storm和Spark-streaming对比","date":"2017-02-28T09:38:36.000Z","updated":"2017-04-14T10:02:27.119Z","comments":true,"path":"2017/02/28/Storm和Spark-streaming对比/","link":"","permalink":"http://amazingwu.xyz/2017/02/28/Storm和Spark-streaming对比/","excerpt":"Spark Streaming与Storm的应用场景对于Storm来说：1、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时金融系统，要求纯实时进行金融交易和分析2、此外，如果对于实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm3、如果还需要针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm4、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择。","text":"Spark Streaming与Storm的应用场景对于Storm来说：1、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时金融系统，要求纯实时进行金融交易和分析2、此外，如果对于实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm3、如果还需要针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm4、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择。 对于Spark Streaming来说：1、如果对上述适用于Storm的三点，一条都不满足的实时场景，即，不要求纯实时，不要求强大可靠的事务机制，不要求动态调整并行度，那么可以考虑使用Spark Streaming2、考虑使用Spark Streaming最主要的一个因素，应该是针对整个项目进行宏观的考虑，即，如果一个项目除了实时计算之外，还包括了离线批处理、交互式查询等业务功能，而且实时计算中，可能还会牵扯到高延迟批处理、交互式查询等功能，那么就应该首选Spark生态，用Spark Core开发离线批处理，用Spark SQL开发交互式查询，用Spark Streaming开发实时计算，三者可以无缝整合，给系统提供非常高的可扩展性 Spark Streaming与Storm的优劣分析事实上，Spark Streaming绝对谈不上比Storm优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。Spark Streaming仅仅在吞吐量上比Storm要优秀，而吞吐量这一点，也是历来挺Spark Streaming，贬Storm的人着重强调的。但是问题是，是不是在所有的实时计算场景下，都那么注重吞吐量？不尽然。因此，通过吞吐量说Spark Streaming强于Storm，不靠谱。事实上，Storm在实时延迟度上，比Spark Streaming就好多了，前者是纯实时，后者是准实时。而且，Storm的事务机制、健壮性 / 容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。 Storm和Spark streaming对比 对比点 storm Spark Streaming \\实时计算模型&emsp; \\纯实时，来一条数据，处理一条数据 \\准实时，对一个时间段内的数据收集起来，作为一个RDD，再处理 \\实时计算延迟度&emsp; \\毫秒级 \\秒级 \\吞吐量&emsp; \\低 \\高 \\事务机制&emsp; \\支持完善 \\支持，但不够完善 \\健壮性 / 容错性&emsp; \\ZooKeeper，Acker，非常强 \\Checkpoint，WAL，一般 \\动态调整并行度&emsp; \\支持 \\不支持","categories":[{"name":"spark","slug":"spark","permalink":"http://amazingwu.xyz/categories/spark/"},{"name":"storm","slug":"spark/storm","permalink":"http://amazingwu.xyz/categories/spark/storm/"}],"tags":[{"name":"spark","slug":"spark","permalink":"http://amazingwu.xyz/tags/spark/"},{"name":"storm","slug":"storm","permalink":"http://amazingwu.xyz/tags/storm/"}]}]}