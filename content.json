{"meta":{"title":"AmazingWu","subtitle":"吴琪个人博客","description":"目前就读于北京理工大学软件学院","author":"AmazingWu","url":"http://yoursite.com"},"pages":[{"title":"关于我","date":"2017-04-09T04:44:43.000Z","updated":"2017-04-12T03:43:10.799Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"地理位置: 教育背景: M.A. : Beijing Institute Of Technology ， Software Engineering ， 2016.09 - Present 个人信息：&emsp;&emsp;目前在北京理工大学软件学院数据科学研究所研究大数据方向 性格：&emsp;&emsp;简单，随性，放纵不羁，爱自由 个人信息：&emsp;&emsp;个人github地址：https://github.com/amazingWu&emsp;&emsp;个人CSDN博客：http://blog.csdn.net/u013668852&emsp;&emsp;个人邮箱：amazingjadewu@gmail.com&emsp;&emsp;欢迎添加我的微信： wq951654775 友情链接：&emsp;&emsp;HaroldLiuChi:北京理工大学软件学院副院长刘驰老师&emsp;&emsp;Guangyu(Ryan) Gao:北京理工大学软件学院高老师&emsp;&emsp;FangHeart的博客:实验室小伙伴FangHeart&emsp;&emsp;wenjiewang的博客：实验室小伙伴wenjiewang&emsp;&emsp;DuanXiong的博客：实验室小伙伴DuanXiong var duoshuoQuery = {short_name:”&lt;%= theme.duoshuo_shortname %&gt;”}; (function() { var ds = document.createElement(‘script’); ds.type = ‘text/javascript’;ds.async = true; ds.src = (document.location.protocol == ‘https:’ ? ‘https:’ : ‘http:’) + ‘//static.duoshuo.com/embed.js’; ds.charset = ‘UTF-8’; (document.getElementsByTagName(‘head’)[0] || document.getElementsByTagName(‘body’)[0]).appendChild(ds); })();"},{"title":"categories","date":"2017-04-09T04:44:03.000Z","updated":"2017-04-09T07:37:05.986Z","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"相册","date":"2017-04-10T11:34:02.000Z","updated":"2017-04-10T11:38:55.614Z","comments":true,"path":"photo/index.html","permalink":"http://yoursite.com/photo/index.html","excerpt":"","text":""},{"title":"感兴趣的项目","date":"2017-04-10T11:34:59.000Z","updated":"2017-04-10T11:38:38.290Z","comments":true,"path":"project/index.html","permalink":"http://yoursite.com/project/index.html","excerpt":"","text":""},{"title":"tags","date":"2017-04-09T04:50:07.000Z","updated":"2017-04-09T07:36:09.336Z","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"动态规划-DAG-硬币问题","slug":"动态规划-DAG-硬币问题","date":"2017-04-17T13:37:21.000Z","updated":"2017-04-17T13:38:27.743Z","comments":true,"path":"2017/04/17/动态规划-DAG-硬币问题/","link":"","permalink":"http://yoursite.com/2017/04/17/动态规划-DAG-硬币问题/","excerpt":"题目：有n种硬币，面值分别为V1,V2,…Vn,每种都有无限多。给定非负整数S，可以选用多少个硬币，使得面值之和恰好为S？输出硬币数目的最小值和最大值！ &emsp;&emsp;如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元？ (表面上这道题可以用贪心算法，但贪心算法无法保证可以求出解，比如1元换成2元的时候)","text":"题目：有n种硬币，面值分别为V1,V2,…Vn,每种都有无限多。给定非负整数S，可以选用多少个硬币，使得面值之和恰好为S？输出硬币数目的最小值和最大值！ &emsp;&emsp;如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元？ (表面上这道题可以用贪心算法，但贪心算法无法保证可以求出解，比如1元换成2元的时候) &emsp;&emsp;首先我们思考一个问题，如何用最少的硬币凑够i元(i&lt;11)？为什么要这么问呢？两个原因：1.当我们遇到一个大问题时，总是习惯把问题的规模变小，这样便于分析讨论。2.这个规模变小后的问题和原来的问题是同质的，除了规模变小，其它的都是一样的，本质上它还是同一个问题(规模变小后的问题其实是原问题的子问题)。 &emsp;&emsp;好了，让我们从最小的i开始吧。当i=0，即我们需要多少个硬币来凑够0元。由于1，3，5都大于0，即没有比0小的币值，因此凑够0元我们最少需要0个硬币。这时候我们发现用一个标记来表示这句“凑够0元我们最少需要0个硬币。 &emsp;&emsp;那么， 我们用d(i)=j来表示凑够i元最少需要j个硬币。于是我们已经得到了d(0)=0，表示凑够0元最小需要0个硬币。当i=1时，只有面值为1元的硬币可用，因此我们拿起一个面值为1的硬币，接下来只需要凑够0元即可，而这个是已经知道答案的，即d(0)=0。所以，d(1)=d(1-1)+1=d(0)+1=0+1=1。 当i=2时， 仍然只有面值为1的硬币可用，于是我拿起一个面值为1的硬币，接下来我只需要再凑够2-1=1元即可(记得要用最小的硬币数量)，而这个答案也已经知道了。所以d(2)=d(2-1)+1=d(1)+1=1+1=2。 &emsp;&emsp;一直到这里，你都可能会觉得，好无聊，感觉像做小学生的题目似的。因为我们一直都只能操作面值为1的硬币！耐心点，让我们看看i=3时的情况。当i=3时，我们能用的硬币就有两种了：1元的和3元的(5元的仍然没用，因为你需要凑的数目是3元！5元太多了亲)。既然能用的硬币有两种，我就有两种方案。如果我拿了一个1元的硬币，我的目标就变为了:凑够3-1=2元需要的最少硬币数量。即d(3)=d(3-1)+1=d(2)+1=2+1=3。这个方案说的是，我拿3个1元的硬币；第二种方案是我拿起一个3元的硬币，我的目标就变成：凑够3-3=0元需要的最少硬币数量。即d(3)=d(3-3)+1=d(0)+1=0+1=1. &emsp;&emsp;这个方案说的是，我拿1个3元的硬币。好了，这两种方案哪种更优呢？ 记得我们可是要用最少的硬币数量来凑够3元的。所以， 选择d(3)=1，怎么来的呢？ &emsp;&emsp;具体是这样得到的：d(3)=min{d(3-1)+1, d(3-3)+1}。 &emsp;&emsp;上文中d(i)表示凑够i元需要的最少硬币数量，我们将它定义为该问题的”状态”，这个状态是怎么找出来的呢？我在另一篇文章中写过：根据子问题定义状态。你找到子问题，状态也就浮出水面了。 &emsp;&emsp;最终我们要求解的问题，可以用这个状态来表示：d(11)，即凑够11元最少需要多少个硬币。 那状态转移方程是什么呢？既然我们用d(i)表示状态，那么状态转移方程自然包含d(i)， 上文中包含状态d(i)的方程是：d(3)=min{d(3-1)+1,d(3-3)+1}。没错，它就是状态转移方程，描述状态之间是如何转移的。当然，我们要对它抽象一下，d(i)=min{ d(i-vj)+1 }，其中i-vj &gt;=0，vj表示第j个硬币的面值; &emsp;&emsp;有了状态和状态转移方程，这个问题基本上也就解决了。 1234567891011121314151617181920212223242526272829303132#include&lt;cstdio&gt; #include&lt;cstring&gt; int d[1000],v[10]; int max(int a, int b) &#123; return a &gt; b ? a : b; &#125; int dpmax(int s,int n) &#123; if (d[s] != -1) return d[s]; d[s] = -10000;//用于设定不能走到终点的路肯定小于能走到终点的路 for (int i = 0;i &lt; n;i++) if (s &gt;= v[i])//等号很关键 //根据公式：max&#123;dpmax(s-v[i])+1&#125;,代码max(d[s], dpmax(s - v[i], n)+1)中的d[s]记录的是上一个值 d[s] = max(d[s], dpmax(s - v[i], n)+1); return d[s]; &#125; int main() &#123; int n, s, i; while (scanf(\"%d%d\", &amp;n, &amp;s) != EOF) &#123; for (i = 0;i &lt; n;i++) scanf(\"%d\", &amp;v[i]); memset(d, -1, sizeof d); d[0] = 0;//用于辨别该路能否走到终点 printf(\"%d\\n\", dpmax(s, n)); &#125; return 0; &#125; 解答转载自http://www.cnblogs.com/sunTin/p/6674945.html","categories":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/categories/算法/"},{"name":"动态规划","slug":"算法/动态规划","permalink":"http://yoursite.com/categories/算法/动态规划/"}],"tags":[{"name":"算法","slug":"算法","permalink":"http://yoursite.com/tags/算法/"},{"name":"动态规划","slug":"动态规划","permalink":"http://yoursite.com/tags/动态规划/"}]},{"title":"maven打造可执行war包","slug":"maven打造可执行jar包","date":"2017-04-07T07:45:55.000Z","updated":"2017-04-12T10:50:26.354Z","comments":true,"path":"2017/04/07/maven打造可执行jar包/","link":"","permalink":"http://yoursite.com/2017/04/07/maven打造可执行jar包/","excerpt":"在开发java Web时，有时我们会使用嵌入式jetty来运行，项目完成后，如果能够直接运行war包从而启动jetty来运行war包那就非常完美了，本文将讲解如何在项目中整合jetty 9，并构造可执行的war包（打包前和打包后都能随时启动）。","text":"在开发java Web时，有时我们会使用嵌入式jetty来运行，项目完成后，如果能够直接运行war包从而启动jetty来运行war包那就非常完美了，本文将讲解如何在项目中整合jetty 9，并构造可执行的war包（打包前和打包后都能随时启动）。1.首先添加jetty 9的依赖（本文暂时只用到了jetty的以下依赖，读者根据自己的项目需要增加）12345678910&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-server&lt;/artifactId&gt; &lt;version&gt;9.2.7.v20150116&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.eclipse.jetty&lt;/groupId&gt; &lt;artifactId&gt;jetty-webapp&lt;/artifactId&gt; &lt;version&gt;9.2.7.v20150116&lt;/version&gt;&lt;/dependency&gt; 2.项目中使用jetty 9。 首先我封装了自己的JettyServer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485public class EmbeddedServer &#123; //public static final Logger logger = LoggerFactory.getLogger(EmbeddedServer.class); // private static final int DEFAULT_BUFFER_SIZE = 16192; protected final Server server = new Server(); public EmbeddedServer(int port,String path) throws IOException&#123; this(port,path,false,null); &#125; /** * use war to start * @param port * @param isWar * @param warPath * @throws IOException */ public EmbeddedServer(int port,boolean isWar,String warPath) throws IOException&#123; this(port,null,isWar,warPath); &#125; private EmbeddedServer(int port, String path,boolean isWar,String warPath) throws IOException &#123; Connector connector = getConnector(port); server.addConnector(connector); WebAppContext application = getWebAppContext(path,isWar,warPath); server.setHandler(application); server.setStopAtShutdown(true); &#125; protected WebAppContext getWebAppContext(String path,boolean isWar,String warPath) &#123; WebAppContext application; if(isWar)&#123; application=new WebAppContext(); application.setWar(warPath); return application; &#125;else&#123; application = new WebAppContext(path, \"/\"); application.setConfigurationDiscovered(true); application.setParentLoaderPriority(true); application.setClassLoader(Thread.currentThread().getContextClassLoader()); return application; &#125; &#125; protected Connector getConnector(int port) throws IOException &#123; HttpConfiguration http_config = new HttpConfiguration(); // this is to enable large header sizes when Kerberos is enabled with AD //final int bufferSize = getBufferSize(); //http_config.setResponseHeaderSize(bufferSize); //http_config.setRequestHeaderSize(bufferSize); ServerConnector connector = new ServerConnector(server, new HttpConnectionFactory(http_config)); connector.setPort(port); connector.setHost(\"0.0.0.0\"); server.addConnector(connector); return connector; &#125; /*protected Integer getBufferSize() &#123; try &#123; Configuration configuration = ApplicationProperties.get(); return configuration.getInt(\"sysimple.jetty.request.buffer.size\", DEFAULT_BUFFER_SIZE); &#125; catch (Exception e) &#123; // do nothing &#125; return DEFAULT_BUFFER_SIZE; &#125;*/ public void start() throws Exception &#123; server.start(); //logger.info(\"********************************************************\"); //logger.info(\"The SySimple Has Started !!!\"); server.join(); &#125; public void stop() &#123; try &#123; server.stop(); &#125; catch (Exception e) &#123; //logger.warn(\"Error during shutdown\", e); &#125; &#125;&#125; 接着可以使用封装好的EmbeddedServer来启动war 12345678910111213141516171819public class StartWeb&#123; private static EmbeddedServer embeddedServer; public static void main(String[] args)&#123; //Start web server int port=3000； try&#123; if(args.length==0)&#123; //该方式能够在开发时快速启动 embeddedServer=new EmbeddedServer(port, \"src/main/webapp\"); &#125;else&#123; //传入war包的路径，该方法能够在打包完成后启动该war包 embeddedServer=new EmbeddedServer(port, true, args[0]); &#125; embeddedServer.start(); &#125;catch(Exception e)&#123; System.exit(0); &#125; &#125;&#125; 注意：打包后如果需要启动war包，需要使用如下的这种批处理命令来启动： 以批处理命令（start.bat）和server.war在同级目录下为例：（以下是start.bat的内容） @echo off set bat_dir=%~dp0 java -jar %bat_dir%/web.war %bat_dir%/web.war 读者可以考虑在代码中得到war包的路径，这样可以在启动时省去传参。 下面是最重要的：使用Maven构建可执行war包 总的来说可执行war包是将war包的结构仿照jar包的结构进行改变，第一个是需要在manifest中标记出主方法，第二个是编译后的代码（包，而非.class）必须放在war包的最外层，最后要能够找到项目的依赖。 ①标记主方法 通过maven-war-plugin在manifest中标记主方法入口 1234567891011&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;org.bit.linc.web.commons.StartWeb&lt;/mainClass&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; ②拷贝（也可以移动）web的所有的代码到war包最外层（使用maven-antrun-plugin） 12345678910111213141516171819202122&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;main-class-placement&lt;/id&gt; &lt;phase&gt;prepare-package&lt;/phase&gt; &lt;configuration&gt; &lt;target&gt; &lt;copy todir=\"$&#123;project.build.directory&#125;/$&#123;project.artifactId&#125;/\"&gt; &lt;fileset dir=\"$&#123;project.build.directory&#125;/classes/\"&gt; &lt;include name=\"**/*.*\" /&gt; &lt;/fileset&gt; &lt;/copy&gt; &lt;/target&gt; &lt;/configuration&gt; &lt;goals&gt; &lt;goal&gt;run&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; ③ 标记所有依赖的位置（将代码拷贝到war最外层后，会出现依赖的类都找不到的情况，因此需要让war包能够查找到这些依赖） 将maven-war-plugin更改为如下内容： 12345678910111213&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-war-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;archive&gt; &lt;manifest&gt; &lt;mainClass&gt;org.bit.linc.web.commons.StartWeb&lt;/mainClass&gt; &lt;addClasspath&gt;true&lt;/addClasspath&gt; &lt;classpathPrefix&gt;WEB-INF/lib&lt;/classpathPrefix&gt; &lt;/manifest&gt; &lt;/archive&gt; &lt;/configuration&gt; &lt;/plugin&gt; 现在可以构建可执行war包了。 以笔者的项目为例：构建的war包中META-INF/MANIFEST.MF会变成如下内容： Manifest-Version: 1.0 Built-By: wubo Build-Jdk: 1.7.0_17 Class-Path: WEB-INF/lib/commons-0.0.2.jar WEB-INF/lib/commons-configur ation-1.8.jar WEB-INF/lib/commons-lang-2.6.jar WEB-INF/lib/commons-lo gging-1.1.1.jar WEB-INF/lib/slf4j-api-1.7.7.jar WEB-INF/lib/slf4j-log 4j12-1.7.7.jar WEB-INF/lib/log4j-1.2.17.jar WEB-INF/lib/plugins-0.0.2 .jar WEB-INF/lib/clusters-0.0.2.jar WEB-INF/lib/monitors-0.0.2.jar WE B-INF/lib/jetty-server-9.2.7.v20150116.jar WEB-INF/lib/javax.servlet- api-3.1.0.jar WEB-INF/lib/jetty-http-9.2.7.v20150116.jar WEB-INF/lib/ jetty-util-9.2.7.v20150116.jar WEB-INF/lib/jetty-io-9.2.7.v20150116.j ar WEB-INF/lib/jetty-webapp-9.2.7.v20150116.jar WEB-INF/lib/jetty-xml -9.2.7.v20150116.jar WEB-INF/lib/jetty-servlet-9.2.7.v20150116.jar WE B-INF/lib/jetty-security-9.2.7.v20150116.jar WEB-INF/lib/gson-2.3.1.j ar Created-By: Apache Maven 3.3.9 Main-Class: org.bit.linc.web.commons.StartWeb Archiver-Version: Plexus Archiver 其中的Class-Path和Main-Class均已经改变。","categories":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"},{"name":"javaWeb","slug":"javaWeb","permalink":"http://yoursite.com/tags/javaWeb/"}]},{"title":"maven多级项目使用slf4j+log4j，以及自定义配置文件路径","slug":"maven多级项目使用slf4j+log4j以及自定义配置文件路径 - 副本","date":"2017-03-23T07:45:55.000Z","updated":"2017-04-12T10:50:47.522Z","comments":true,"path":"2017/03/23/maven多级项目使用slf4j+log4j以及自定义配置文件路径 - 副本/","link":"","permalink":"http://yoursite.com/2017/03/23/maven多级项目使用slf4j+log4j以及自定义配置文件路径 - 副本/","excerpt":"我的maven多级结构如下： sysimple |--integration |--commons |--pom.xml |--plugins |--pom.xml |--web |--pom.xml |--pom.xml 其中依赖情况是：","text":"我的maven多级结构如下： sysimple |--integration |--commons |--pom.xml |--plugins |--pom.xml |--web |--pom.xml |--pom.xml 其中依赖情况是： web依赖于commons和plugins。plugins依赖于commons。integration中定义了打包的方法与资源文件。 首先在sysimple/pom.xml中管理slf4j的版本： 在&lt;dependencyManagement&gt;&lt;/dependencyManagement&gt;中间添加： &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.7&lt;/version&gt; &lt;/dependency&gt; 由于所有的模块均引用commons，因此只需要在commons中添加slf4j的依赖即可： &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;/dependency&gt; 下面即可使用slf4j，在需要使用的地方以如下方式使用： 123456public class StartWeb &#123; private static final Logger logger = LoggerFactory.getLogger(StartWeb.class); public static void main(String[] args)&#123; logger.info(\"this is a example\"); &#125;&#125; 默认情况下，slf4j-log4j会在src/main/java中查找log4j.properties，如果需要指定配置文件的位置，需要在启动时手动加入Jvm的参数，我的例子中添加了-Dlog4j.configuration=file:../integration/conf/sysimple-log4j.properties。在使用绝对路径时是不需要使用file:的，linux端也不需要file:。在运行的时候，slf4j会根据你指定的路径去加载配置文件。配置文件的内容我给出以下例子， 读者可以另行查找配置文件的格式： log4j.rootLogger=INFO,system.out log4j.appender.system.out=org.apache.log4j.ConsoleAppender log4j.appender.system.out.layout=org.apache.log4j.PatternLayout log4j.appender.system.out.layout.ConversionPattern=SysimpleServer Logger--&gt;%5p{%F:%L}-%m%n log4j.logger.thisProject.file=INFO,thisProject.file.out log4j.appender.thisProject.file.out=org.apache.log4j.DailyRollingFileAppender log4j.appender.thisProject.file.out.File=../integration/logs/sysimple-logs.log log4j.appender.thisProject.file.out.layout=org.apache.log4j.PatternLayout","categories":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://yoursite.com/tags/maven/"},{"name":"log4j","slug":"log4j","permalink":"http://yoursite.com/tags/log4j/"}]},{"title":"jvm垃圾收集算法","slug":"jvm垃圾收集算法","date":"2017-03-15T11:05:36.000Z","updated":"2017-04-12T11:07:19.847Z","comments":true,"path":"2017/03/15/jvm垃圾收集算法/","link":"","permalink":"http://yoursite.com/2017/03/15/jvm垃圾收集算法/","excerpt":"来源：JVM虚拟机 标记-清除法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。 之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 它的主要不足有两个：==一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片==，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。","text":"来源：JVM虚拟机 标记-清除法最基础的收集算法是“标记-清除”（Mark-Sweep）算法，如同它的名字一样，算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收所有被标记的对象，它的标记过程其实在前一节讲述对象标记判定时已经介绍过了。 之所以说它是最基础的收集算法，是因为后续的收集算法都是基于这种思路并对其不足进行改进而得到的。 它的主要不足有两个：==一个是效率问题，标记和清除两个过程的效率都不高；另一个是空间问题，标记清除之后会产生大量不连续的内存碎片==，空间碎片太多可能会导致以后在程序运行过程中需要分配较大对象时，无法找到足够的连续内存而不得不提前触发另一次垃圾收集动作。 复制算法为了解决效率问题，一种称为“复制”（Copying）的收集算法出现了，它将可用==内存按容量划分为大小相等的两块，每次只使用其中的一块==。 ==当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉==。 这样使得每次都是对整个半区进行内存回收，内存分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可，实现简单，运行高效。 只是这种算法的代价是将内存缩小为了原来的一半，未免太高了一点。 复制算法的执行过程如图3-3所示。 现在的商业虚拟机都采用这种收集算法来回收新生代，IBM公司的专门研究表明，新生代中的对象98%是“朝生夕死”的。所以并不需要按照1:1的比例来划分内存空间，==而是将内存分为一块较大的Eden空间和两块较小的Survivor空间==，每次使用Eden和其中一块Survivor[1]。当回收时，将Eden和Survivor中还存活着的对象一次性地复制到另外一块Survivor空间上，最后清理掉Eden和刚才用过的Survivor空间。 HotSpot虚拟机默认Eden和Survivor的大小比例是8:1，也就是每次新生代中可用内存空间为整个新生代容量的90%（80%+10%），只有10%的内存会被“浪费”。 当然，98%的对象可回收只是一般场景下的数据，我们没有办法保证每次回收都只有不多于10%的对象存活，当Survivor空间不够用时，需要依赖其他内存（这里指老年代）进行分配担保（Handle Promotion）。 标记整理算法复制收集算法在对象存活率较高时就要进行较多的复制操作，效率将会变低。 更关键的是，如果不想浪费50%的空间，就需要有额外的空间进行分配担保，以应对被使用的内存中所有对象都100%存活的极端情况，所以在老年代一般不能直接选用这种算法。根据老年代的特点，有人提出了另外一种“标记-整理”（Mark-Compact）算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。 分代收集算法当前商业虚拟机的垃圾收集都采用“分代收集”（Generational Collection）算法，这种算法并没有什么新的思想，==只是根据对象存活周期的不同将内存划分为几块==。 一般是把Java堆分为新生代和老年代，这样就可以==根据各个年代的特点采用最适当的收集算法==。 在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。 而老年代中因为对象存活率高、 没有额外空间对它进行分配担保，就必须使用“标记—清理”或者“标记—整理”算法来进行回收。","categories":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"java对象的创建过程","slug":"java对象的创建过程","date":"2017-03-15T10:52:36.000Z","updated":"2017-04-12T11:00:19.888Z","comments":true,"path":"2017/03/15/java对象的创建过程/","link":"","permalink":"http://yoursite.com/2017/03/15/java对象的创建过程/","excerpt":"对象的创建过程 来源：JVM虚拟机 Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出来。在语言层面上，创建对象（例如克隆、反序列化）通常仅仅是一个new关键字而已，而在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建又是怎样一个过程呢？","text":"对象的创建过程 来源：JVM虚拟机 Java是一门面向对象的编程语言，在Java程序运行过程中无时无刻都有对象被创建出来。在语言层面上，创建对象（例如克隆、反序列化）通常仅仅是一个new关键字而已，而在虚拟机中，对象（文中讨论的对象限于普通Java对象，不包括数组和Class对象等）的创建又是怎样一个过程呢？虚拟机遇到一条new指令时，==首先将去检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已被加载、解析和初始化过==。 如果没有，那必须先执行相应的类加载过程。 ==在类加载检查通过后，接下来虚拟机将为新生对象分配内存==。==对象所需内存的大小在类加载完成后便可完全确定==（如何确定将在2.3.2节中介绍），为对象分配空间的任务等同于把一块确定大小的内存从Java堆中划分出来。++假设Java堆中内存是绝对规整的++，所有用过的内存都放在一边，空闲的内存放在另一边，中间放着一个指针作为分界点的指示器，那所分配内存就仅仅是把那个指针向空闲空间那边挪动一段与对象大小相等的距离，这种分配方式称为“++==指针碰撞==++”（Bump the Pointer）。如果Java堆中的内存并++不是规整的++，已使用的内存和空闲的内存相互交错，那就没有办法简单地进行指针碰撞了，虚拟机就必须维护一个列表，记录上哪些内存块是可用的，在分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的记录，这种分配方式称为“==空闲列表==”（Free List）。 选择哪种分配方式由Java堆是否规整决定，而Java堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。 因此，在使用Serial、 ParNew等带Compact过程的收集器时，系统采用的分配算法是指针碰撞，而使用CMS这种基于Mark-Sweep算法的收集器时，通常采用空闲列表。 除如何划分可用空间之外，还有另外一个需要考虑的问题是对象创建在虚拟机中是非常频繁的行为，即使是仅仅修改一个指针所指向的位置，在并发情况下也并不是线程安全的，可能出现正在给对象A分配内存，指针还没来得及修改，对象B又同时使用了原来的指针来分配内存的情况。解决这个问题有两种方案，==一种是对分配内存空间的动作进行同步处理==——实际上虚拟机采用CAS配上失败重试的方式保证更新操作的原子性；==另一种是把内存分配的动作按照线程划分在不同的空间之中进行，即每个线程在Java堆中预先分配一小块内存，称为本地线程分配缓冲（Thread Local Allocation Buffer,TLAB）==。哪个线程要分配内存，就在哪个线程的TLAB上分配，只有TLAB用完并分配新的TLAB时，才需要同步锁定。虚拟机是否使用TLAB，可以通过-XX：+/-UseTLAB参数来设定。 内存分配完成后，==虚拟机需要将分配到的内存空间都初始化为零值（不包括对象头），如果使用TLAB，这一工作过程也可以提前至TLAB分配时进行==。 这一步操作保证了对象的实例字段在Java代码中可以不赋初始值就直接使用，程序能访问到这些字段的数据类型所对应的零值。 接下来，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、 如何才能找到类的元数据信息、 对象的哈希码、对象的GC分代年龄等信息。 这些信息存放在对象的对象头（Object Header）之中。根据虚拟机当前的运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。 关于对象头的具体内容，稍后再做详细介绍。 在上面工作都完成之后，从虚拟机的视角来看，一个新的对象已经产生了，但从Java程序的视角来看，对象创建才刚刚开始——＜init＞方法还没有执行，所有的字段都还为零。所以，一般来说（由字节码中是否跟随invokespecial指令所决定），==执行new指令之后会接着执行＜init＞方法==，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。","categories":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/categories/jvm/"}],"tags":[{"name":"jvm","slug":"jvm","permalink":"http://yoursite.com/tags/jvm/"}]},{"title":"Storm和Spark streaming对比","slug":"Storm和Spark-streaming对比","date":"2017-02-28T09:38:36.000Z","updated":"2017-04-14T10:02:27.119Z","comments":true,"path":"2017/02/28/Storm和Spark-streaming对比/","link":"","permalink":"http://yoursite.com/2017/02/28/Storm和Spark-streaming对比/","excerpt":"Spark Streaming与Storm的应用场景对于Storm来说：1、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时金融系统，要求纯实时进行金融交易和分析2、此外，如果对于实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm3、如果还需要针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm4、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择。","text":"Spark Streaming与Storm的应用场景对于Storm来说：1、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如实时金融系统，要求纯实时进行金融交易和分析2、此外，如果对于实时计算的功能中，要求可靠的事务机制和可靠性机制，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm3、如果还需要针对高峰低峰时间段，动态调整实时计算程序的并行度，以最大限度利用集群资源（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm4、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择。 对于Spark Streaming来说：1、如果对上述适用于Storm的三点，一条都不满足的实时场景，即，不要求纯实时，不要求强大可靠的事务机制，不要求动态调整并行度，那么可以考虑使用Spark Streaming2、考虑使用Spark Streaming最主要的一个因素，应该是针对整个项目进行宏观的考虑，即，如果一个项目除了实时计算之外，还包括了离线批处理、交互式查询等业务功能，而且实时计算中，可能还会牵扯到高延迟批处理、交互式查询等功能，那么就应该首选Spark生态，用Spark Core开发离线批处理，用Spark SQL开发交互式查询，用Spark Streaming开发实时计算，三者可以无缝整合，给系统提供非常高的可扩展性 Spark Streaming与Storm的优劣分析事实上，Spark Streaming绝对谈不上比Storm优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。Spark Streaming仅仅在吞吐量上比Storm要优秀，而吞吐量这一点，也是历来挺Spark Streaming，贬Storm的人着重强调的。但是问题是，是不是在所有的实时计算场景下，都那么注重吞吐量？不尽然。因此，通过吞吐量说Spark Streaming强于Storm，不靠谱。事实上，Storm在实时延迟度上，比Spark Streaming就好多了，前者是纯实时，后者是准实时。而且，Storm的事务机制、健壮性 / 容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark生态技术栈中，因此Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。 Storm和Spark streaming对比 对比点 storm Spark Streaming \\实时计算模型&emsp; \\纯实时，来一条数据，处理一条数据 \\准实时，对一个时间段内的数据收集起来，作为一个RDD，再处理 \\实时计算延迟度&emsp; \\毫秒级 \\秒级 \\吞吐量&emsp; \\低 \\高 \\事务机制&emsp; \\支持完善 \\支持，但不够完善 \\健壮性 / 容错性&emsp; \\ZooKeeper，Acker，非常强 \\Checkpoint，WAL，一般 \\动态调整并行度&emsp; \\支持 \\不支持","categories":[{"name":"spark","slug":"spark","permalink":"http://yoursite.com/categories/spark/"},{"name":"storm","slug":"spark/storm","permalink":"http://yoursite.com/categories/spark/storm/"}],"tags":[{"name":"spark","slug":"spark","permalink":"http://yoursite.com/tags/spark/"},{"name":"storm","slug":"storm","permalink":"http://yoursite.com/tags/storm/"}]}]}